{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:16.610049Z",
     "iopub.status.busy": "2021-09-19T18:50:16.609764Z",
     "iopub.status.idle": "2021-09-19T18:50:21.37895Z",
     "shell.execute_reply": "2021-09-19T18:50:21.378226Z",
     "shell.execute_reply.started": "2021-09-19T18:50:16.609973Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/util.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare files and labels using get_dummies\n",
    "df_train=pd.read_csv('Train_Data.csv',header=None)\n",
    "\n",
    "df_train.columns=['FileNames','Labels']\n",
    "\n",
    "train_df=pd.DataFrame()\n",
    "\n",
    "for c in range(0,len(df_train)):\n",
    "    train_df['FileNames']=df_train['FileNames'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "    train_df['Labels']=df_train['Labels'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "\n",
    "train_labels=train_df['Labels']\n",
    "train_new_label=pd.get_dummies(train_labels)\n",
    "\n",
    "train_new_df = pd.concat([train_df['FileNames'], train_new_label], axis=1)\n",
    "train_new_df['COVID']=train_new_df['COVID'].astype(np.float32)\n",
    "train_new_df['Normal']=train_new_df['Normal'].astype(np.float32)\n",
    "train_new_df['Viral Pneumonia']=train_new_df['Viral Pneumonia'].astype(np.float32)\n",
    "train_new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling of minority classes in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling of the traning dataset\n",
    "\n",
    "df_train=train_new_df\n",
    "\n",
    "#Extract only COVID data\n",
    "is_COVID=df['COVID']==1\n",
    "Co_df=df[is_COVID]\n",
    "Co_df.head\n",
    "Co_df.shape\n",
    "\n",
    "#Extract only Pneumonia data\n",
    "is_P=df['Viral Pneumonia']==1\n",
    "P_df=df[is_P]\n",
    "P_df.head\n",
    "P_df.shape\n",
    "\n",
    "#Extract only Normal data\n",
    "is_N=df['Normal']==1\n",
    "N_df=df[is_N]\n",
    "N_df.head\n",
    "N_df.shape\n",
    "\n",
    "##Oversample Covid Data with 2.8x\n",
    "sampled_Co_df=Co_df.sample(frac=2.8, replace=True, random_state=1)\n",
    "\n",
    "sampled_Co_df.head()\n",
    "\n",
    "#oversample pneumonia data with 7.5x\n",
    "sampled_P_df=P_df.sample(frac=7.5, replace=True, random_state=1)\n",
    "\n",
    "sampled_P_df.head()\n",
    "\n",
    "#Concatenate all class togehter into one dataframe\n",
    "Oversampled_train_df=pd.concat([sampled_N_df,sampled_P_df])\n",
    "Oversampled_train_df=pd.concat([Oversampled_train_df,Co_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:21.380918Z",
     "iopub.status.busy": "2021-09-19T18:50:21.380644Z",
     "iopub.status.idle": "2021-09-19T18:50:21.466116Z",
     "shell.execute_reply": "2021-09-19T18:50:21.465426Z",
     "shell.execute_reply.started": "2021-09-19T18:50:21.380883Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare files and labels using get_dummies\n",
    "df_test=pd.read_csv('Test_Data.csv',header=None)\n",
    "\n",
    "df_test.columns=['FileNames','Labels']\n",
    "\n",
    "test_df=pd.DataFrame()\n",
    "\n",
    "for c in range(0,len(df_test)):\n",
    "    test_df['FileNames']=df_test['FileNames'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "    test_df['Labels']=df_test['Labels'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "\n",
    "test_labels=test_df['Labels']\n",
    "test_new_label=pd.get_dummies(test_labels)\n",
    "\n",
    "test_new_df = pd.concat([test_df['FileNames'], test_new_label], axis=1)\n",
    "test_new_df['COVID']=test_new_df['COVID'].astype(np.float32)\n",
    "test_new_df['Normal']=test_new_df['Normal'].astype(np.float32)\n",
    "test_new_df['Viral Pneumonia']=test_new_df['Viral Pneumonia'].astype(np.float32)\n",
    "test_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare files and labels using get_dummies\n",
    "df_valid=pd.read_csv('Validate_Data.csv',header=None)\n",
    "\n",
    "df_valid.columns=['FileNames','Labels']\n",
    "\n",
    "validt_df=pd.DataFrame()\n",
    "\n",
    "for c in range(0,len(df_valid)):\n",
    "    valid_df['FileNames']=df_valid['FileNames'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "    valid_df['Labels']=df_valid['Labels'].apply(lambda x: (x.replace(\"'\",'')))\n",
    "\n",
    "valid_labels=valid_df['Labels']\n",
    "valid_new_label=pd.get_dummies(valid_labels)\n",
    "\n",
    "valid_new_df = pd.concat([valid_df['FileNames'], valid_new_label], axis=1)\n",
    "valid_new_df['COVID']=valid_new_df['COVID'].astype(np.float32)\n",
    "valid_new_df['Normal']=valid_new_df['Normal'].astype(np.float32)\n",
    "valid_new_df['Viral Pneumonia']=valid_new_df['Viral Pneumonia'].astype(np.float32)\n",
    "valid_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:21.477012Z",
     "iopub.status.busy": "2021-09-19T18:50:21.476399Z",
     "iopub.status.idle": "2021-09-19T18:50:21.487774Z",
     "shell.execute_reply": "2021-09-19T18:50:21.487009Z",
     "shell.execute_reply.started": "2021-09-19T18:50:21.476976Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "  \n",
    "    print(\"getting train generator...\") \n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization= True)\n",
    "    \n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:21.48951Z",
     "iopub.status.busy": "2021-09-19T18:50:21.489168Z",
     "iopub.status.idle": "2021-09-19T18:50:21.503012Z",
     "shell.execute_reply": "2021-09-19T18:50:21.50222Z",
     "shell.execute_reply.started": "2021-09-19T18:50:21.489474Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "\n",
    "    print(\"getting train and valid generators...\")\n",
    "    # get generator to sample dataset\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=IMAGE_DIR, \n",
    "        x_col=x_col, \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:21.504742Z",
     "iopub.status.busy": "2021-09-19T18:50:21.50416Z",
     "iopub.status.idle": "2021-09-19T18:50:49.020374Z",
     "shell.execute_reply": "2021-09-19T18:50:49.018991Z",
     "shell.execute_reply.started": "2021-09-19T18:50:21.504705Z"
    }
   },
   "outputs": [],
   "source": [
    "#use oversampled training set as the training data here\n",
    "labels=['COVID','Normal','Viral Pneumonia']\n",
    "\n",
    "IMAGE_DIR = \"../input/segmented_Xrays/\"\n",
    "train_generator = get_train_generator(Oversampled_train_df, IMAGE_DIR, \"FileNames\", labels)\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_new_df, test_new_df, Oversampled_train_df, IMAGE_DIR,  \"FileNames\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:49.729827Z",
     "iopub.status.busy": "2021-09-19T18:50:49.729546Z",
     "iopub.status.idle": "2021-09-19T18:50:57.359966Z",
     "shell.execute_reply": "2021-09-19T18:50:57.359211Z",
     "shell.execute_reply.started": "2021-09-19T18:50:49.729792Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model  =EfficientNetB7(weights='imagenet',include_top=False)\n",
    "\n",
    "#base_model = DenseNet121(weights='../input/library/densenet.hdf5', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T18:50:57.361728Z",
     "iopub.status.busy": "2021-09-19T18:50:57.361452Z",
     "iopub.status.idle": "2021-09-19T19:38:24.70696Z",
     "shell.execute_reply": "2021-09-19T19:38:24.706253Z",
     "shell.execute_reply.started": "2021-09-19T18:50:57.361696Z"
    }
   },
   "outputs": [],
   "source": [
    "#train the net\n",
    "history = model.fit(train_generator, \n",
    "                    batch_size=10,\n",
    "                    validation_data=valid_generator,\n",
    "                    steps_per_epoch=100, \n",
    "                    validation_steps=25, \n",
    "                    epochs = 100)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Accuracy Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:38:24.708867Z",
     "iopub.status.busy": "2021-09-19T19:38:24.70861Z",
     "iopub.status.idle": "2021-09-19T19:38:26.012034Z",
     "shell.execute_reply": "2021-09-19T19:38:26.011262Z",
     "shell.execute_reply.started": "2021-09-19T19:38:24.708832Z"
    }
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Trained_EfficientNetB7_Oversampling.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:38:26.02285Z",
     "iopub.status.busy": "2021-09-19T19:38:26.022415Z",
     "iopub.status.idle": "2021-09-19T19:39:03.824854Z",
     "shell.execute_reply": "2021-09-19T19:39:03.824065Z",
     "shell.execute_reply.started": "2021-09-19T19:38:26.022816Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prediction of new data in test data\n",
    "predicted_vals = model.predict(test_generator, steps = len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:39:03.828659Z",
     "iopub.status.busy": "2021-09-19T19:39:03.828459Z",
     "iopub.status.idle": "2021-09-19T19:39:04.135401Z",
     "shell.execute_reply": "2021-09-19T19:39:04.134632Z",
     "shell.execute_reply.started": "2021-09-19T19:39:03.828636Z"
    }
   },
   "outputs": [],
   "source": [
    "#this code was derived from https://www.coursera.org/learn/ai-for-medical-diagnosis\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "import tensorflow as tf #I added\n",
    "random.seed(a=None, version=2)\n",
    "\n",
    "set_verbosity(INFO)\n",
    "\n",
    "\n",
    "\n",
    "def get_mean_std_per_batch(image_path, df, H=320, W=320):\n",
    "    sample_data = []\n",
    "    for idx, img in enumerate(df.sample(100)[\"FileNames\"].values):\n",
    "        # path = image_dir + img\n",
    "        sample_data.append(\n",
    "            np.array(image.load_img(image_path, target_size=(H, W))))\n",
    "\n",
    "    mean = np.mean(sample_data[0])\n",
    "    std = np.std(sample_data[0])\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def load_image(img, image_dir, df, preprocess=True, H=320, W=320):\n",
    "    \"\"\"Load and preprocess image.\"\"\"\n",
    "    img_path = image_dir + img\n",
    "    mean, std = get_mean_std_per_batch(img_path, df, H=H, W=W)\n",
    "    x = image.load_img(img_path, target_size=(H, W))\n",
    "    if preprocess:\n",
    "        x -= mean\n",
    "        x /= std\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "def grad_cam(input_model, image, cls, layer_name, H=320, W=320):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "def compute_gradcam(model, img, image_dir, df, labels, selected_labels,\n",
    "                    layer_name='bn'):\n",
    "    preprocessed_input = load_image(img, image_dir, df)\n",
    "    predictions = model.predict(preprocessed_input)\n",
    "\n",
    "    print(\"Loading original image\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(151)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(load_image(img, image_dir, df, preprocess=False), cmap='gray')\n",
    "\n",
    "    j = 1\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in selected_labels:\n",
    "            print(f\"Generating gradcam for class {labels[i]}\")\n",
    "            gradcam = grad_cam(model, preprocessed_input, i, layer_name)\n",
    "            plt.subplot(151 + j)\n",
    "            plt.title(f\"{labels[i]}: p={predictions[0][i]:.3f}\")\n",
    "            plt.axis('off')\n",
    "            plt.imshow(load_image(img, image_dir, df, preprocess=False),\n",
    "                       cmap='gray')\n",
    "            plt.imshow(gradcam, cmap='jet', alpha=min(0.5, predictions[0][i]))\n",
    "            j += 1\n",
    "def get_roc_curve(labels, predicted_vals, generator):\n",
    "    auc_roc_vals = []\n",
    "    for i in range(len(labels)):\n",
    "        try:\n",
    "            gt = generator.labels[:, i]\n",
    "            pred = predicted_vals[:, i]\n",
    "            auc_roc = roc_auc_score(gt, pred)\n",
    "            auc_roc_vals.append(auc_roc)\n",
    "            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n",
    "            plt.figure(1, figsize=(10, 10))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(fpr_rf, tpr_rf,\n",
    "                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n",
    "            plt.xlabel('False positive rate')\n",
    "            plt.ylabel('True positive rate')\n",
    "            plt.title('ROC curve')\n",
    "            plt.legend(loc='best')\n",
    "        except:\n",
    "            print(\n",
    "                f\"Error in generating ROC curve for {labels[i]}. \"\n",
    "                f\"Dataset lacks enough examples.\"\n",
    "            )\n",
    "    plt.show()\n",
    "    return auc_roc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:39:04.137288Z",
     "iopub.status.busy": "2021-09-19T19:39:04.13661Z",
     "iopub.status.idle": "2021-09-19T19:39:04.389037Z",
     "shell.execute_reply": "2021-09-19T19:39:04.388354Z",
     "shell.execute_reply.started": "2021-09-19T19:39:04.137246Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot ROC curve\n",
    "labels=['COVID','Normal','Viral Pneumonia']\n",
    "auc_rocs = get_roc_curve(labels, predicted_vals, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:39:04.390501Z",
     "iopub.status.busy": "2021-09-19T19:39:04.390087Z",
     "iopub.status.idle": "2021-09-19T19:40:05.729135Z",
     "shell.execute_reply": "2021-09-19T19:40:05.728428Z",
     "shell.execute_reply.started": "2021-09-19T19:39:04.390464Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_results = model.predict(valid_generator, steps = len(valid_generator))\n",
    "test_results = model.predict(test_generator, steps = len(test_generator))\n",
    "\n",
    "\n",
    "# the labels for prediction values in our dataset\n",
    "pred_labels = [l + \"_pred\" for l in labels]\n",
    "\n",
    "print(valid_results.shape)\n",
    "\n",
    "results_valid=pd.DataFrame()\n",
    "results_valid[labels]=valid_new_df[labels]\n",
    "\n",
    "\n",
    "for i,x in enumerate(pred_labels):\n",
    "    results_valid[x]=valid_results[:,i]\n",
    "\n",
    "results_test=pd.DataFrame()\n",
    "results_test[labels]=test_new_df[labels]\n",
    "\n",
    "\n",
    "for i,x in enumerate(pred_labels):\n",
    "    results_test[x]=test_results[:,i]\n",
    "print(results_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:40:05.732045Z",
     "iopub.status.busy": "2021-09-19T19:40:05.731844Z",
     "iopub.status.idle": "2021-09-19T19:40:05.909682Z",
     "shell.execute_reply": "2021-09-19T19:40:05.908997Z",
     "shell.execute_reply.started": "2021-09-19T19:40:05.732021Z"
    }
   },
   "outputs": [],
   "source": [
    "y = test_df[labels].values\n",
    "pred = test_result[pred_labels].values\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(x = labels, height= y.sum(axis=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:40:05.922492Z",
     "iopub.status.busy": "2021-09-19T19:40:05.922206Z",
     "iopub.status.idle": "2021-09-19T19:40:05.966431Z",
     "shell.execute_reply": "2021-09-19T19:40:05.96561Z",
     "shell.execute_reply.started": "2021-09-19T19:40:05.922459Z"
    }
   },
   "outputs": [],
   "source": [
    "#function for evaluation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "\n",
    "def get_true_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 1))\n",
    "\n",
    "\n",
    "def get_true_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 0))\n",
    "\n",
    "\n",
    "def get_false_neg(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == False) & (y == 1))\n",
    "\n",
    "\n",
    "def get_false_pos(y, pred, th=0.5):\n",
    "    pred_t = (pred > th)\n",
    "    return np.sum((pred_t == True) & (y == 0))\n",
    "\n",
    "\n",
    "def get_performance_metrics(y, pred, class_labels, tp=get_true_pos,\n",
    "                            tn=get_true_neg, fp=get_false_pos,\n",
    "                            fn=get_false_neg,\n",
    "                            acc=None, prevalence=None, spec=None,\n",
    "                            sens=None, ppv=None, npv=None, auc=None, f1=None,\n",
    "                            thresholds=[]):\n",
    "    if len(thresholds) != len(class_labels):\n",
    "        thresholds = [.5] * len(class_labels)\n",
    "\n",
    "    columns = [\"\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"Prevalence\",\n",
    "               \"Sensitivity\",\n",
    "               \"Specificity\", \"PPV\", \"NPV\", \"AUC\", \"F1\", \"Threshold\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(class_labels)):\n",
    "        df.loc[i] = [\"\"] + [0] * (len(columns) - 1)\n",
    "        df.loc[i][0] = class_labels[i]\n",
    "        df.loc[i][1] = round(tp(y[:, i], pred[:, i]),\n",
    "                             3) if tp != None else \"Not Defined\"\n",
    "        df.loc[i][2] = round(tn(y[:, i], pred[:, i]),\n",
    "                             3) if tn != None else \"Not Defined\"\n",
    "        df.loc[i][3] = round(fp(y[:, i], pred[:, i]),\n",
    "                             3) if fp != None else \"Not Defined\"\n",
    "        df.loc[i][4] = round(fn(y[:, i], pred[:, i]),\n",
    "                             3) if fn != None else \"Not Defined\"\n",
    "        df.loc[i][5] = round(acc(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if acc != None else \"Not Defined\"\n",
    "        df.loc[i][6] = round(prevalence(y[:, i]),\n",
    "                             3) if prevalence != None else \"Not Defined\"\n",
    "        df.loc[i][7] = round(sens(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if sens != None else \"Not Defined\"\n",
    "        df.loc[i][8] = round(spec(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if spec != None else \"Not Defined\"\n",
    "        df.loc[i][9] = round(ppv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                             3) if ppv != None else \"Not Defined\"\n",
    "        df.loc[i][10] = round(npv(y[:, i], pred[:, i], thresholds[i]),\n",
    "                              3) if npv != None else \"Not Defined\"\n",
    "        df.loc[i][11] = round(auc(y[:, i], pred[:, i]),\n",
    "                              3) if auc != None else \"Not Defined\"\n",
    "        df.loc[i][12] = round(f1(y[:, i], pred[:, i] > thresholds[i]),\n",
    "                              3) if f1 != None else \"Not Defined\"\n",
    "        df.loc[i][13] = round(thresholds[i], 3)\n",
    "\n",
    "    df = df.set_index(\"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_confidence_intervals(class_labels, statistics):\n",
    "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
    "    for i in range(len(class_labels)):\n",
    "        mean = statistics.mean(axis=1)[i]\n",
    "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
    "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
    "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_curve(gt, pred, target_names, curve='roc'):\n",
    "    for i in range(len(target_names)):\n",
    "        if curve == 'roc':\n",
    "            curve_function = roc_curve\n",
    "            auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
    "            xlabel = \"False positive rate\"\n",
    "            ylabel = \"True positive rate\"\n",
    "            a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.plot(a, b, label=label)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "        elif curve == 'prc':\n",
    "            precision, recall, _ = precision_recall_curve(gt[:, i], pred[:, i])\n",
    "            average_precision = average_precision_score(gt[:, i], pred[:, i])\n",
    "            label = target_names[i] + \" Avg.: %.3f \" % average_precision\n",
    "            plt.figure(1, figsize=(7, 7))\n",
    "            plt.step(recall, precision, where='post', label=label)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
    "                       fancybox=True, ncol=1)\n",
    "def get_accuracy(y, pred, th=0.5):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "        pred (np.array): model output, size (n_examples)\n",
    "        th (float): cutoff value for positive prediction from model\n",
    "    Returns:\n",
    "        accuracy (float): accuracy of predictions at threshold\n",
    "    \"\"\"\n",
    "    accuracy = 0.0\n",
    " \n",
    "    \n",
    "    # get TP, FP, TN, FN using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # Compute accuracy using TP, FP, TN, FN\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def get_prevalence(y):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions at threshold.\n",
    "\n",
    "    Args:\n",
    "        y (np.array): ground truth, size (n_examples)\n",
    "    Returns:\n",
    "        prevalence (float): prevalence of positive cases\n",
    "    \"\"\"\n",
    "    prevalence = 0.0\n",
    "\n",
    "    \n",
    "    prevalence = np.mean(y)\n",
    "    \n",
    "\n",
    "    \n",
    "    return prevalence\n",
    "\n",
    "\n",
    "def get_sensitivity(y, pred, th=0.5):\n",
    " \n",
    "    sensitivity = 0.0\n",
    "    \n",
    "    \n",
    "    # get TP and FN using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # use TP and FN to compute sensitivity\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    \n",
    " \n",
    "    return sensitivity\n",
    "\n",
    "def get_specificity(y, pred, th=0.5):\n",
    "\n",
    "    specificity = 0.0\n",
    "    \n",
    "    \n",
    "    # get TN and FP using our previously defined functions\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "    \n",
    "    # use TN and FP to compute specificity \n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "    \n",
    "    return specificity\n",
    "\n",
    "def get_ppv(y, pred, th=0.5):\n",
    " \n",
    "    PPV = 0.0\n",
    "\n",
    "    \n",
    "    # get TP and FP using our previously defined functions\n",
    "    TP = true_positives(y, pred, th)\n",
    "    FP = false_positives(y, pred, th)\n",
    "\n",
    "    # use TP and FP to compute PPV\n",
    "    PPV = TP / (TP + FP)\n",
    "\n",
    "    \n",
    "    return PPV\n",
    "\n",
    "def get_npv(y, pred, th=0.5):\n",
    "  \n",
    "    NPV = 0.0\n",
    "    \n",
    "    # get TN and FN using our previously defined functions\n",
    "    TN = true_negatives(y, pred, th)\n",
    "    FN = false_negatives(y, pred, th)\n",
    "\n",
    "    # use TN and FN to compute NPV\n",
    "    NPV = TN / (TN + FN)\n",
    "\n",
    "    \n",
    "    return NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T19:40:05.968213Z",
     "iopub.status.busy": "2021-09-19T19:40:05.967708Z",
     "iopub.status.idle": "2021-09-19T19:40:06.018923Z",
     "shell.execute_reply": "2021-09-19T19:40:06.018078Z",
     "shell.execute_reply.started": "2021-09-19T19:40:05.968177Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate the performance of the classifier using evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "metrics=get_performance_metrics(y, pred, labels,acc=get_accuracy, prevalence=get_prevalence,sens=get_sensitivity, spec=get_specificity,ppv=get_ppv, npv=get_npv,auc=roc_auc_score,f1=f1_score)\n",
    "print(metrics)\n",
    "\n",
    "#save the predicted output and assoicated probability to csv files.\n",
    "metrics.to_csv('Predicted_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of indicative regions in CXRs\n",
    "df = test_new_df\n",
    "IMAGE_DIR = \"../input/segmented-xrays/\"\n",
    "\n",
    "labels=['COVID','Normal','Viral Pneumonia']\n",
    "\n",
    "\n",
    "# only show the labels with AUC\n",
    "labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:3]\n",
    "compute_gradcam(model, 'COVID-3026.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
